# Security Audit Report: v0.6.x Functionality

**Date:** October 26, 2023
**Target Version:** v0.6.x (The Conductors)
**Auditor:** Cybersecurity/Blue Hat Expert

## 1. Executive Summary

This audit evaluates the security of the functionality designed and planned for Lexichord v0.6.x, as well as the existing underlying infrastructure it relies on.

**Key Findings:**
*   **CRITICAL:** The "Secure Vault" implementation on Linux and macOS uses a weak key derivation mechanism that effectively amounts to obfuscation rather than encryption. This places all stored secrets (including the planned LLM API keys) at risk of compromise by any local user or process with file read access.
*   **HIGH:** The planned integration of LLM providers (OpenAI, Anthropic) in v0.6.x relies heavily on this insecure vault for API key storage.
*   **MEDIUM:** The "Teams" tier functionality, particularly regarding RAG (Retrieval-Augmented Generation) and Context Assembly, may introduce data isolation risks if deployed in a shared environment, as the current search service lacks user-level access controls.

## 2. Detailed Findings

### 2.1. Critical: Weak Encryption in `AesFileBackend` (Insecure Storage)

**Severity:** Critical
**Component:** `Lexichord.Host.Services.Security.AesFileBackend` (Existing Infrastructure)
**Impact:** Total compromise of stored secrets (API keys, passwords) on Linux and macOS.

**Analysis:**
The v0.6.x roadmap relies on `ISecureVault` to store provider API keys (`openai:api-key`, `anthropic:api-key`). The current implementation for Linux and macOS (`UnixSecureVault`) attempts to use `LibSecretBackend` but falls back to `AesFileBackend` because `LibSecret` support is currently stubbed out/not implemented.

The `AesFileBackend` derives its encryption key using the following inputs:
1.  **Machine ID:** `/etc/machine-id` (often world-readable) or `Environment.MachineName` (publicly known).
2.  **User Name:** `Environment.UserName` (easily guessable or known).
3.  **Salt:** A `.salt` file stored alongside the secrets in the vault directory.

**Vulnerability:**
An attacker with read access to the vault directory (e.g., via a compromised backup, shared file system, or malware running as another user with broad read permissions) can trivially reconstruct the encryption key:
1.  Read the `.salt` file.
2.  Read `/etc/machine-id` (or guess the hostname).
3.  Guess the username.
4.  Run the PBKDF2 derivation to get the key.
5.  Decrypt all secrets.

This mechanism does not rely on a user-supplied secret (like a login password or master password) or a secure hardware element (TPM/Secure Enclave). It is essentially obfuscation.

### 2.2. High: API Key Exposure via The Gateway

**Severity:** High
**Component:** v0.6.1 (The Gateway)
**Impact:** Leakage of user's paid API credits and potential usage of their accounts for malicious purposes.

**Analysis:**
The v0.6.1 design explicitly states: "Keys stored via `ISecureVault` (v0.0.6a) with provider-prefixed keys".
Because the underlying storage is insecure (see 2.1), the primary asset introduced in v0.6.x (LLM connectivity) is built on a compromised foundation. Users believing their keys are "securely stored" will be misled.

### 2.3. Medium: RAG Search Access Control (Lateral Movement)

**Severity:** Medium (Potential)
**Component:** `Lexichord.Modules.RAG.Search.PgVectorSearchService`
**Impact:** Unauthorized access to sensitive documents in a "Teams" environment.

**Analysis:**
The v0.6.x roadmap introduces "Teams" tier features including "advanced context assembly". If the "Teams" tier implies a shared knowledge base or database between users, the current implementation of `PgVectorSearchService` is insufficient.
*   The `SearchAsync` method accepts `SearchOptions`, which *can* include a `DocumentFilter`.
*   However, the service itself **does not enforce** any user-based permissions or Row-Level Security (RLS).
*   Any caller to `ISemanticSearchService` can query the entire vector index.

If the architecture is a single-user local desktop app, this risk is low (user owns the DB). If it involves a shared Postgres instance for a team, this is a major privacy vulnerability.

### 2.4. Low: Design Review - Prompt & Template Injection

**Severity:** Low / Informational
**Component:** v0.6.3 (The Template Engine)

**Analysis:**
The roadmap describes a `MustachePromptRenderer` that allows user input (`{{user_input}}`) and context injection.
*   **Mustache Safety:** Mustache is logic-less and generally safe from Code Execution, provided the renderer (Stubble) is not configured to allow arbitrary method invocation (default is safe).
*   **Prompt Injection:** The system is inherently susceptible to "Jailbreaking" or Prompt Injection by the end-user (since the user *is* the one chatting). However, if *external* data (e.g., from a document or RAG chunk) contains malicious instructions (Indirect Prompt Injection), the LLM might be tricked into misbehaving. This is an inherent LLM risk, not a code vulnerability, but the UI should clearly distinguish between "System/Context" and "User" data to the extent possible.
*   **Recursive Rendering:** Ensure that the content of variables (like `user_input`) is not *re-processed* as a template. (Standard Mustache does not do this, so it should be safe).

### 2.5. Low: Design Review - Context Injection Path Traversal

**Severity:** Low
**Component:** v0.6.3d (Context Injection Service)

**Analysis:**
The `ContextRequest` record includes `string? CurrentDocumentPath`.
```csharp
public record ContextRequest(string? CurrentDocumentPath, ...);
```
The future `IContextInjector` implementation must validate that this path:
1.  Exists.
2.  Is within the allowed workspace/sandbox.
3.  The user has permission to read it.

Failure to validate could allow an attacker (e.g., via a malicious plugin or IPC call) to inject arbitrary system files into the prompt context, exfiltrating them to the LLM provider.

## 3. Recommendations

### 3.1. Fix `ISecureVault` Implementation (Immediate Priority)
The current `AesFileBackend` is not secure for production use.
1.  **Implement System Keyring Support:** Prioritize the implementation of `LibSecretBackend` (Linux) using proper P/Invoke to `libsecret` (Gnome Keyring / KWallet).
2.  **macOS Support:** Implement a `KeychainBackend` using macOS Keychain Services.
3.  **Fallback Hardening:** If a fallback to file-based encryption is necessary (e.g., headless servers), it **MUST** require a user-supplied master password to derive the encryption key. Do not rely solely on machine attributes.

### 3.2. Clarify "Teams" Architecture & Enforce Permissions
If the "Teams" tier involves shared infrastructure:
1.  **Row-Level Security:** Implement RLS in PostgreSQL to restrict access to `Chunks` based on `UserId` or `TeamId`.
2.  **Service-Level Checks:** Update `ISemanticSearchService` to accept a `IUserContext` and enforce filters automatically, rather than relying on the caller to provide a `DocumentFilter`.

### 3.3. Secure Design for Context Injection
1.  **Path Validation:** Ensure `ContextInjector` uses `IWorkspaceService` (or similar) to resolve and validate paths, preventing traversal outside the authorized workspace.
2.  **Data Sanitization:** When injecting RAG chunks or document content, wrap them in clear delimiters (e.g., XML tags `<context>...</context>`) to help the LLM distinguish data from instructions.

### 3.4. Operational Security
1.  **SSL/TLS:** Ensure `IHttpClientFactory` used for OpenAI/Anthropic connections enforces valid SSL certificates.
2.  **Token Limits:** Enforce strict token limits on "Context" to prevent cost denial-of-service (DoS) where a malicious document fills the context window.
